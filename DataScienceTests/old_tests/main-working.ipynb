{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "torch.manual_seed(99)\n",
    "\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.875</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.937</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.062</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.125</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.187</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97237</th>\n",
       "      <td>24.812</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97239</th>\n",
       "      <td>24.750</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97241</th>\n",
       "      <td>24.500</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97242</th>\n",
       "      <td>24.437</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97244</th>\n",
       "      <td>24.562</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48623 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature  month  day  hour  minute\n",
       "1           22.875      1   21     0      30\n",
       "2           22.937      1   21     1       0\n",
       "5           23.062      1   21     1      30\n",
       "7           23.125      1   21     2       0\n",
       "8           23.187      1   21     2      30\n",
       "...            ...    ...  ...   ...     ...\n",
       "97237       24.812     10   29    21      30\n",
       "97239       24.750     10   29    22       0\n",
       "97241       24.500     10   29    22      30\n",
       "97242       24.437     10   29    23       0\n",
       "97244       24.562     10   29    23      30\n",
       "\n",
       "[48623 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/datasets/historical.data\")\n",
    "#df = df.set_index(\"date\").sort_index(ascending=True)\n",
    "df = df.sort_values(by=\"date\",ascending=True)\n",
    "df[\"month\"] = df.apply(lambda x: int(x[\"date\"].split(\"-\")[1])-1, axis=1) # category indexed to 0\n",
    "df[\"day\"] = df.apply(lambda x: int(x[\"date\"].split(\" \")[0].split(\"-\")[2])-1, axis=1) # category indexed to 0\n",
    "df[\"hour\"] = df.apply(lambda x: int(x[\"date\"].split(\" \")[1].split(\":\")[0]), axis=1)\n",
    "df[\"minute\"] = df.apply(lambda x: int(x[\"date\"].split(\" \")[1].split(\":\")[1]), axis=1)\n",
    "df = df.drop([\"date\"], axis=1)\n",
    "#df.apply(lambda x: x[\"date\"].split(\" \")[0].split(\"-\")[1] + \"-\" + x[\"date\"].split(\" \")[0].split(\"-\")[2], axis=1)\n",
    "#display(df)\n",
    "df_inside = df.loc[df[\"label\"] == \"inside\"].drop([\"label\"], axis=1)\n",
    "df_outside = df.loc[df[\"label\"] == \"outside\"].drop([\"label\"], axis=1)\n",
    "print(\"inside\")\n",
    "display(df_inside)\n",
    "#print(\"outside\")\n",
    "#display(df_outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "[[22.875  1.    21.     0.    30.   ]\n",
      " [22.937  1.    21.     1.     0.   ]\n",
      " [23.062  1.    21.     1.    30.   ]\n",
      " ...\n",
      " [23.562  4.    11.     8.     0.   ]\n",
      " [23.437  4.    11.     8.    30.   ]\n",
      " [23.562  4.    11.     9.     0.   ]]\n",
      "test\n",
      "[[23.625  4.    11.     9.    30.   ]\n",
      " [23.437  4.    11.    10.     0.   ]\n",
      " [23.562  4.    11.    10.    30.   ]\n",
      " ...\n",
      " [24.     7.    20.    15.     0.   ]\n",
      " [24.312  7.    20.    15.    30.   ]\n",
      " [24.625  7.    20.    16.     0.   ]]\n",
      "ivs\n",
      "[[24.375  7.    20.    16.    30.   ]\n",
      " [24.625  7.    20.    17.     0.   ]\n",
      " [24.562  7.    20.    17.    30.   ]\n",
      " ...\n",
      " [24.75  10.    29.    22.     0.   ]\n",
      " [24.5   10.    29.    22.    30.   ]\n",
      " [24.437 10.    29.    23.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inside_arr=np.array(df_inside)\n",
    "outside_arr=np.array(df_outside)\n",
    "\n",
    "#print(inside_arr)\n",
    "\n",
    "#train_test_split(inside_arr, shuffle=False)\n",
    "\n",
    "def split_data(arr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    total_len,_=arr.shape\n",
    "\n",
    "    train_p = 0.80\n",
    "    test_p = 0.10\n",
    "    ivs_p = 0.10\n",
    "\n",
    "    train_len = round(total_len*train_p)\n",
    "    test_len = round(total_len*test_p)\n",
    "    ivs_len = round(total_len*ivs_p)\n",
    "\n",
    "    model_len = train_len+test_len\n",
    "\n",
    "    total_used_len = model_len+ivs_len\n",
    "\n",
    "    train = arr[:train_len]\n",
    "    test = arr[train_len:model_len]\n",
    "    ivs = arr[model_len:total_used_len]\n",
    "\n",
    "    return train, test, ivs\n",
    "\n",
    "\n",
    "inside_train, inside_test, inside_ivs = split_data(inside_arr)\n",
    "\n",
    "print(\"train\")\n",
    "print(inside_train)\n",
    "print(\"test\")\n",
    "print(inside_test)\n",
    "print(\"ivs\")\n",
    "print(inside_ivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Wanted Predictions: 5.0\n"
     ]
    }
   ],
   "source": [
    "# 2h30\n",
    "\n",
    "per_min = (2*60) + 30\n",
    "per_30_mins = per_min / 30\n",
    "\n",
    "print(\"Number of Wanted Predictions: \" + str(per_30_mins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-step-ahead (auto-regressive)\n",
    "<br>\n",
    "One-step-ahead (auto-regressive with exogenous inputs)\n",
    "<br>\n",
    "Recursive\n",
    "<br>\n",
    "MIMO\n",
    "<br>\n",
    "Direct\n",
    "<br>\n",
    "Hybrid (Recursive and Direct)\n",
    "<br>\n",
    "Hybrid (Direct and MIMO)\n",
    "<br>\n",
    "<br>\n",
    "MIMO is good too, but it would be more accurate and faster to compute several dedicated models for each step instead of all in a batch.\n",
    "<br>\n",
    "Direct and Hybrid(Direct and MIMO) are on top - they can execute all\n",
    "<br>\n",
    "<br>\n",
    "Hybrid(Direct and MIMO) = [2,2,1] predictive models\n",
    "<br>\n",
    "Direct = [+-,1,1,1,1] predictive models\n",
    "<br>\n",
    "<br>\n",
    "Other tests that could be implemented would be creating a Long Short-Term Memory model, trying out some kind of BERT model with months as categorial variables, or classical statistic models like SVMs or Decision Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_train_0 = []\n",
    "inside_train_X_0 = []\n",
    "inside_train_Y_0 = []\n",
    "\n",
    "imput_dim_df = 48 # 24H input\n",
    "\n",
    "_temp_arr = []\n",
    "_n = 0\n",
    "for temp, month, day, hour, minute in inside_train:\n",
    "    if len(_temp_arr) < imput_dim_df:\n",
    "        _temp_arr.append(temp)\n",
    "        _n+=1\n",
    "        continue\n",
    "    else:\n",
    "        _temp_arr.pop(0)\n",
    "        _temp_arr.append(temp)\n",
    "\n",
    "    if _n < len(inside_train)-1:\n",
    "        inside_train_X_0.append(_temp_arr)\n",
    "        inside_train_Y_0.append(inside_train[_n+1][0])\n",
    "        \n",
    "        inside_train_0.append((torch.Tensor(_temp_arr), inside_train[_n+1][0]))\n",
    "\n",
    "    _n+=1\n",
    "\n",
    "inside_train_X_0 = np.array(inside_train_X_0, dtype=np.float32)\n",
    "inside_train_Y_0 = np.array(inside_train_Y_0, dtype=np.float32)\n",
    "#inside_train_X_0 = torch.from_numpy(np.array(inside_train_X_0, dtype=np.float32))\n",
    "#inside_train_Y_0 = torch.from_numpy(np.array(inside_train_Y_0, dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_test_0 = []\n",
    "inside_test_X_0 = []\n",
    "inside_test_Y_0 = []\n",
    "\n",
    "imput_dim_df = 48 # 24H input\n",
    "\n",
    "_temp_arr = []\n",
    "_n = 0\n",
    "for temp, month, day, hour, minute in inside_test:\n",
    "    if len(_temp_arr) < imput_dim_df:\n",
    "        _temp_arr.append(temp)\n",
    "        _n+=1\n",
    "        continue\n",
    "    else:\n",
    "        _temp_arr.pop(0)\n",
    "        _temp_arr.append(temp)\n",
    "\n",
    "    if _n < len(inside_test)-1:\n",
    "        inside_test_X_0.append(_temp_arr)\n",
    "        inside_test_Y_0.append(inside_test[_n+1][0])\n",
    "        \n",
    "        inside_test_0.append((torch.Tensor(_temp_arr), inside_test[_n+1][0]))\n",
    "\n",
    "    _n+=1\n",
    "\n",
    "inside_test_X_0 = np.array(inside_test_X_0, dtype=np.float32)\n",
    "inside_test_Y_0 = np.array(inside_test_Y_0, dtype=np.float32)\n",
    "#inside_test_X_0 = torch.from_numpy(np.array(inside_test_X_0, dtype=np.float36))\n",
    "#inside_test_Y_0 = torch.from_numpy(np.array(inside_test_Y_0, dtype=np.float36))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38849\n",
      "4813\n"
     ]
    }
   ],
   "source": [
    "#print(inside_train_X_0.size())\n",
    "#print(inside_train_Y_0.size())\n",
    "print(len(inside_train_X_0))\n",
    "print(len(inside_test_X_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776.98\n",
      "38800\n"
     ]
    }
   ],
   "source": [
    "_ = len(inside_train_X_0) / 50\n",
    "print(len(inside_train_X_0) / 50)\n",
    "print(int(_) * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "train_data = inside_train_Y_0[0:38649]\n",
    "test_data = inside_test_Y_0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "#train_data_normalized = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window = 50 # 48H + margin input\n",
    "#train_window = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 0.3542,  0.3698,  0.3542,  0.3698,  0.3698,  0.3226,  0.2753,  0.2596,\n",
       "           0.2596,  0.2437,  0.1966,  0.1966,  0.1651,  0.1651,  0.1492,  0.1336,\n",
       "           0.1492,  0.1336,  0.1177,  0.1021,  0.0862,  0.0706,  0.0706,  0.0390,\n",
       "           0.0232,  0.0075,  0.0232,  0.0232, -0.0083, -0.0240, -0.0240, -0.0555,\n",
       "          -0.0555, -0.0240, -0.0083,  0.0075,  0.0547,  0.1177,  0.1966,  0.2281,\n",
       "           0.1807,  0.2281,  0.2596,  0.3226,  0.3068,  0.2753,  0.3542,  0.3542,\n",
       "           0.3226,  0.3383], device='cuda:0'),\n",
       "  tensor([0.3383], device='cuda:0')),\n",
       " (tensor([ 0.3698,  0.3542,  0.3698,  0.3698,  0.3226,  0.2753,  0.2596,  0.2596,\n",
       "           0.2437,  0.1966,  0.1966,  0.1651,  0.1651,  0.1492,  0.1336,  0.1492,\n",
       "           0.1336,  0.1177,  0.1021,  0.0862,  0.0706,  0.0706,  0.0390,  0.0232,\n",
       "           0.0075,  0.0232,  0.0232, -0.0083, -0.0240, -0.0240, -0.0555, -0.0555,\n",
       "          -0.0240, -0.0083,  0.0075,  0.0547,  0.1177,  0.1966,  0.2281,  0.1807,\n",
       "           0.2281,  0.2596,  0.3226,  0.3068,  0.2753,  0.3542,  0.3542,  0.3226,\n",
       "           0.3383,  0.3383], device='cuda:0'),\n",
       "  tensor([0.3383], device='cuda:0')),\n",
       " (tensor([ 0.3542,  0.3698,  0.3698,  0.3226,  0.2753,  0.2596,  0.2596,  0.2437,\n",
       "           0.1966,  0.1966,  0.1651,  0.1651,  0.1492,  0.1336,  0.1492,  0.1336,\n",
       "           0.1177,  0.1021,  0.0862,  0.0706,  0.0706,  0.0390,  0.0232,  0.0075,\n",
       "           0.0232,  0.0232, -0.0083, -0.0240, -0.0240, -0.0555, -0.0555, -0.0240,\n",
       "          -0.0083,  0.0075,  0.0547,  0.1177,  0.1966,  0.2281,  0.1807,  0.2281,\n",
       "           0.2596,  0.3226,  0.3068,  0.2753,  0.3542,  0.3542,  0.3226,  0.3383,\n",
       "           0.3383,  0.3383], device='cuda:0'),\n",
       "  tensor([0.3226], device='cuda:0')),\n",
       " (tensor([ 0.3698,  0.3698,  0.3226,  0.2753,  0.2596,  0.2596,  0.2437,  0.1966,\n",
       "           0.1966,  0.1651,  0.1651,  0.1492,  0.1336,  0.1492,  0.1336,  0.1177,\n",
       "           0.1021,  0.0862,  0.0706,  0.0706,  0.0390,  0.0232,  0.0075,  0.0232,\n",
       "           0.0232, -0.0083, -0.0240, -0.0240, -0.0555, -0.0555, -0.0240, -0.0083,\n",
       "           0.0075,  0.0547,  0.1177,  0.1966,  0.2281,  0.1807,  0.2281,  0.2596,\n",
       "           0.3226,  0.3068,  0.2753,  0.3542,  0.3542,  0.3226,  0.3383,  0.3383,\n",
       "           0.3383,  0.3226], device='cuda:0'),\n",
       "  tensor([0.3068], device='cuda:0')),\n",
       " (tensor([ 0.3698,  0.3226,  0.2753,  0.2596,  0.2596,  0.2437,  0.1966,  0.1966,\n",
       "           0.1651,  0.1651,  0.1492,  0.1336,  0.1492,  0.1336,  0.1177,  0.1021,\n",
       "           0.0862,  0.0706,  0.0706,  0.0390,  0.0232,  0.0075,  0.0232,  0.0232,\n",
       "          -0.0083, -0.0240, -0.0240, -0.0555, -0.0555, -0.0240, -0.0083,  0.0075,\n",
       "           0.0547,  0.1177,  0.1966,  0.2281,  0.1807,  0.2281,  0.2596,  0.3226,\n",
       "           0.3068,  0.2753,  0.3542,  0.3542,  0.3226,  0.3383,  0.3383,  0.3383,\n",
       "           0.3226,  0.3068], device='cuda:0'),\n",
       "  tensor([0.2911], device='cuda:0'))]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = LSTM().to(device)\n",
    "    loss_function = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    return model, loss_function, optimizer\n",
    "model, loss_function, optimizer = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.00002032\n",
      "epoch:  24 loss: 0.0001778315\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "model, loss_function, optimizer = load_model()\n",
    "\n",
    "for i in range(epochs):\n",
    "    _ix = -1\n",
    "    for seq, labels in train_inout_seq:\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _ix +=1\n",
    "        \n",
    "        if torch.isnan(seq).any().item():\n",
    "            print(f\"nan values in seq at {_ix}\")\n",
    "            continue\n",
    "\n",
    "        if pd.isna(labels.item()):\n",
    "            print(f\"nan labels at {_ix}\")\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "        if pd.isna(y_pred.item()):\n",
    "            print(f\"nan preds at {_ix}\")\n",
    "            continue\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        if pd.isna(single_loss.item()):\n",
    "            print(f\"nan loss at {_ix}\")\n",
    "            raise\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5903587341308594, 0.5432186126708984, 0.5588479042053223, 0.5273370742797852, 0.4486861228942871, 0.49582624435424805, 0.49582624435424805, 0.4801969528198242, 0.4486861228942871, 0.4486861228942871, 0.46431541442871094, 0.46431541442871094, 0.43280458450317383, 0.3856644630432129, 0.4012937545776367, 0.41717529296875, 0.4012937545776367, 0.3856644630432129, 0.43280458450317383, 0.4012937545776367, 0.43280458450317383, 0.4486861228942871, 0.5432186126708984, 0.5588479042053223, 0.4486861228942871, 0.43280458450317383, 0.46431541442871094, 0.5432186126708984, 0.6062402725219727, 0.5903587341308594, 0.6062402725219727, 0.5432186126708984, 0.6692619323730469, 0.5432186126708984, 0.5432186126708984, 0.5273370742797852, 0.6377511024475098, 0.6218695640563965, 0.6692619323730469, 0.6533803939819336, 0.6533803939819336, 0.6377511024475098, 0.6218695640563965, 0.6218695640563965, 0.6377511024475098, 0.6062402725219727, 0.5903587341308594, 0.5747294425964355, 0.5903587341308594, 0.5747294425964355]\n"
     ]
    }
   ],
   "source": [
    "fut_pred = 12\n",
    "\n",
    "test_inputs = train_data_normalized[-train_window:].tolist()\n",
    "print(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(test_inputs[-train_window:]).to(device)\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        test_inputs.append(model(seq).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43280458450317383,\n",
       " 0.3856644630432129,\n",
       " 0.4012937545776367,\n",
       " 0.41717529296875,\n",
       " 0.4012937545776367,\n",
       " 0.3856644630432129,\n",
       " 0.43280458450317383,\n",
       " 0.4012937545776367,\n",
       " 0.43280458450317383,\n",
       " 0.4486861228942871,\n",
       " 0.5432186126708984,\n",
       " 0.5588479042053223,\n",
       " 0.4486861228942871,\n",
       " 0.43280458450317383,\n",
       " 0.46431541442871094,\n",
       " 0.5432186126708984,\n",
       " 0.6062402725219727,\n",
       " 0.5903587341308594,\n",
       " 0.6062402725219727,\n",
       " 0.5432186126708984,\n",
       " 0.6692619323730469,\n",
       " 0.5432186126708984,\n",
       " 0.5432186126708984,\n",
       " 0.5273370742797852,\n",
       " 0.6377511024475098,\n",
       " 0.6218695640563965,\n",
       " 0.6692619323730469,\n",
       " 0.6533803939819336,\n",
       " 0.6533803939819336,\n",
       " 0.6377511024475098,\n",
       " 0.6218695640563965,\n",
       " 0.6218695640563965,\n",
       " 0.6377511024475098,\n",
       " 0.6062402725219727,\n",
       " 0.5903587341308594,\n",
       " 0.5747294425964355,\n",
       " 0.5903587341308594,\n",
       " 0.5747294425964355,\n",
       " 0.5856366753578186,\n",
       " 0.5953073501586914,\n",
       " 0.6032483577728271,\n",
       " 0.6102455854415894,\n",
       " 0.6169114112854004,\n",
       " 0.6236931681632996,\n",
       " 0.6307205557823181,\n",
       " 0.6380606293678284,\n",
       " 0.6456950306892395,\n",
       " 0.6535345315933228,\n",
       " 0.6614481210708618,\n",
       " 0.6692706942558289]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[fut_pred:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.29326766]\n",
      " [24.33163014]\n",
      " [24.36313123]\n",
      " [24.39088845]\n",
      " [24.41733104]\n",
      " [24.44423351]\n",
      " [24.47211037]\n",
      " [24.50122762]\n",
      " [24.53151244]\n",
      " [24.56261086]\n",
      " [24.59400319]\n",
      " [24.62503446]]\n"
     ]
    }
   ],
   "source": [
    "actual_predictions = scaler.inverse_transform(np.array(test_inputs[train_window:] ).reshape(-1, 1))\n",
    "print(actual_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.727251]]\n",
      "23.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#train_data_normalized = scaler.fit_transform(inside_test_X_0.reshape(-1, 1))\n",
    "#\n",
    "#fut_pred = 12\n",
    "#\n",
    "#test_inputs = train_data_normalized[-train_window:].tolist()\n",
    "#print(test_inputs)\n",
    "#\n",
    "#model.eval()\n",
    "#\n",
    "#for i in range(fut_pred):\n",
    "#    seq = torch.FloatTensor(test_inputs[-train_window:]).to(device)\n",
    "#    with torch.no_grad():\n",
    "#        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "#                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "#        test_inputs.append(model(seq).item())\n",
    "\n",
    "def predict(input):\n",
    "    X = scaler.fit_transform(input.reshape(-1, 1))\n",
    "    X = seq = torch.FloatTensor(X).to(device)\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        preds = model(X)\n",
    "        Y = np.array(preds.cpu())\n",
    "    actual_predictions = scaler.inverse_transform(Y.reshape(-1, 1))\n",
    "    return actual_predictions\n",
    "\n",
    "print(predict(inside_test_X_0[0:49]))\n",
    "print(inside_test_Y_0[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    hidden_layer_size: int\n",
    "    lstm: nn.LSTM\n",
    "    linear: nn.Linear\n",
    "    hidden_cell: tuple[torch.Tensor, torch.Tensor]\n",
    "    scaler: MinMaxScaler\n",
    "    device: str\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def predict(self, input):\n",
    "        X = scaler.fit_transform(input.reshape(-1, 1))\n",
    "\n",
    "    def train(self, train_data, train_window = 50):\n",
    "\n",
    "        # Initiate loss function and optimizer\n",
    "\n",
    "        loss_function = nn.MSELoss().to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # Scale\n",
    "        \n",
    "        train_data_normalized = self.scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "        train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1).to(self.device)\n",
    "\n",
    "        # Create sequences\n",
    "        \n",
    "        train_inout_seq = []\n",
    "        L = len(train_data_normalized)\n",
    "        for i in range(L-train_window):\n",
    "            train_seq = train_data_normalized[i:i+train_window]\n",
    "            train_label = train_data_normalized[i+train_window:i+train_window+1]\n",
    "            train_inout_seq.append((train_seq ,train_label))\n",
    "        \n",
    "        # Train the model\n",
    "\n",
    "        for i in range(epochs):\n",
    "            _ix = -1\n",
    "            for seq, labels in train_inout_seq:\n",
    "                seq = seq.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                _ix +=1\n",
    "                \n",
    "                if torch.isnan(seq).any().item():\n",
    "                    print(f\"nan values in seq at {_ix}\")\n",
    "                    continue\n",
    "\n",
    "                if pd.isna(labels.item()):\n",
    "                    print(f\"nan labels at {_ix}\")\n",
    "                    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "                                torch.zeros(1, 1, self.hidden_layer_size).to(device))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                if pd.isna(y_pred.item()):\n",
    "                    print(f\"nan preds at {_ix}\")\n",
    "                    continue\n",
    "\n",
    "                single_loss = loss_function(y_pred, labels)\n",
    "                if pd.isna(single_loss.item()):\n",
    "                    print(f\"nan loss at {_ix}\")\n",
    "                    raise\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if i%25 == 1:\n",
    "                print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "        # Finalize\n",
    "        self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.00002032\n",
      "epoch:  24 loss: 0.0001778315\n"
     ]
    }
   ],
   "source": [
    "def train(train_data, train_window = 50):\n",
    "\n",
    "    # Initiate loss function and optimizer\n",
    "\n",
    "    loss_function = nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Scale\n",
    "    \n",
    "    train_data_normalized = self.scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "    train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1).to(self.device)\n",
    "\n",
    "    # Create sequences\n",
    "    \n",
    "    train_inout_seq = []\n",
    "    L = len(train_data_normalized)\n",
    "    for i in range(L-train_window):\n",
    "        train_seq = train_data_normalized[i:i+train_window]\n",
    "        train_label = train_data_normalized[i+train_window:i+train_window+1]\n",
    "        train_inout_seq.append((train_seq ,train_label))\n",
    "    \n",
    "    # Train the model\n",
    "\n",
    "    for i in range(epochs):\n",
    "        _ix = -1\n",
    "        for seq, labels in train_inout_seq:\n",
    "            seq = seq.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            _ix +=1\n",
    "            \n",
    "            if torch.isnan(seq).any().item():\n",
    "                print(f\"nan values in seq at {_ix}\")\n",
    "                continue\n",
    "\n",
    "            if pd.isna(labels.item()):\n",
    "                print(f\"nan labels at {_ix}\")\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(device))\n",
    "\n",
    "            y_pred = self(seq)\n",
    "            if pd.isna(y_pred.item()):\n",
    "                print(f\"nan preds at {_ix}\")\n",
    "                continue\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            if pd.isna(single_loss.item()):\n",
    "                print(f\"nan loss at {_ix}\")\n",
    "                raise\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if i%25 == 1:\n",
    "            print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "    # Finalize\n",
    "    self.eval()\n",
    "\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "epochs = 25\n",
    "model, loss_function, optimizer = load_model()\n",
    "\n",
    "for i in range(epochs):\n",
    "    _ix = -1\n",
    "    for seq, labels in train_inout_seq:\n",
    "        seq = seq.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        _ix +=1\n",
    "        \n",
    "        if torch.isnan(seq).any().item():\n",
    "            print(f\"nan values in seq at {_ix}\")\n",
    "            continue\n",
    "\n",
    "        if pd.isna(labels.item()):\n",
    "            print(f\"nan labels at {_ix}\")\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "        if pd.isna(y_pred.item()):\n",
    "            print(f\"nan preds at {_ix}\")\n",
    "            continue\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        if pd.isna(single_loss.item()):\n",
    "            print(f\"nan loss at {_ix}\")\n",
    "            raise\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
