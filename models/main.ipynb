{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "torch.manual_seed(99)\n",
    "\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def printRegStatistics(truth, preds):\n",
    "    print(\"The RVE is: \", explained_variance_score(truth, preds))\n",
    "    print(\"The rmse is: \", mean_squared_error(truth, preds, squared=False))\n",
    "    corr, pval = pearsonr(truth, preds)\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "    print(\"The Maximum Error is is: \", max_error(truth, preds))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(truth, preds))\n",
    "\n",
    "def split_data(arr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    total_len,_=arr.shape\n",
    "\n",
    "    train_p = 0.80\n",
    "    test_p = 0.10\n",
    "    ivs_p = 0.10\n",
    "\n",
    "    train_len = round(total_len*train_p)\n",
    "    test_len = round(total_len*test_p)\n",
    "    ivs_len = round(total_len*ivs_p)\n",
    "\n",
    "    model_len = train_len+test_len\n",
    "\n",
    "    total_used_len = model_len+ivs_len\n",
    "\n",
    "    train = arr[:train_len]\n",
    "    test = arr[train_len:model_len]\n",
    "    ivs = arr[model_len:total_used_len]\n",
    "\n",
    "    return train, test, ivs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    output_size: int\n",
    "\n",
    "    hidden_layer_size: int\n",
    "    lstm: nn.LSTM\n",
    "    linear: nn.Linear\n",
    "    hidden_cell: tuple[torch.Tensor, torch.Tensor]\n",
    "    scaler: MinMaxScaler\n",
    "    device: str\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def predict(self, input):\n",
    "        X = self.scaler.fit_transform(input.reshape(-1, 1))\n",
    "        X = seq = torch.FloatTensor(X).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            self.hidden = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "            preds = self(X)\n",
    "            Y = np.array(preds.cpu())\n",
    "        actual_predictions = self.scaler.inverse_transform(Y.reshape(-1, 1))\n",
    "        return actual_predictions\n",
    "\n",
    "    def set_device(self, device = None):\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        elif device == \"cpu\" or device == \"cuda\":\n",
    "            self.device = device\n",
    "        print(self.device)\n",
    "        \n",
    "        self.to(self.device)\n",
    "\n",
    "    def train(self, train_data, train_window = 50, epochs = 100):\n",
    "\n",
    "        # Initiate loss function and optimizer\n",
    "\n",
    "        loss_function = nn.MSELoss().to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        # Scale\n",
    "        \n",
    "        train_data_normalized = self.scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "        train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1).to(self.device)\n",
    "\n",
    "        # Create sequences\n",
    "        \n",
    "        train_inout_seq = []\n",
    "        L = len(train_data_normalized)\n",
    "        for i in range(L-train_window):\n",
    "            train_seq = train_data_normalized[i:i+train_window]\n",
    "            # TODO - offset on the start for direct decoding with several (5) of these models giving (5) concurrent predictions?\n",
    "            train_label = train_data_normalized[i+train_window:i+train_window+self.output_size]\n",
    "            train_inout_seq.append((train_seq ,train_label))\n",
    "        \n",
    "        # Train the model\n",
    "\n",
    "        for i in range(epochs):\n",
    "            _ix = -1\n",
    "            for seq, labels in train_inout_seq:\n",
    "                seq = seq.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                if len(labels) != self.output_size:\n",
    "                    continue\n",
    "\n",
    "                _ix +=1\n",
    "                \n",
    "                #if torch.isnan(seq).any().item():\n",
    "                #    print(f\"nan values in seq at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                #if pd.isna(labels.item()):\n",
    "                #    print(f\"nan labels at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                                torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                #if pd.isna(y_pred.item()):\n",
    "                #    print(f\"nan preds at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                single_loss = loss_function(y_pred, labels)\n",
    "                #if pd.isna(single_loss.item()):\n",
    "                #    print(f\"nan loss at {_ix}\")\n",
    "                #    raise\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if i%25 == 1:\n",
    "                print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "        # Finalize\n",
    "        #self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomForestRegressor(RandomForestRegressor):\n",
    "\n",
    "    n_preds: int\n",
    "    n_estimators: int\n",
    "    \n",
    "    def __init__(self, n_preds=4,n_estimators=100):\n",
    "        super().__init__(n_estimators=100)\n",
    "        self.n_preds = n_preds\n",
    "        self.n_estimators = n_estimators\n",
    "    \n",
    "    def total_predict(self, outside_val_curr: float, outside_val_preds: np.array, inside_val_curr: float):\n",
    "        inside_preds = []\n",
    "        assert len(outside_val_preds) == self.n_preds\n",
    "        for i in range(self.n_preds):\n",
    "            if i == 0:\n",
    "                input = np.array([outside_val_curr, outside_val_preds[i][0], inside_val_curr], dtype=\"object\").reshape(1, -1)\n",
    "            else:\n",
    "                input = np.array([outside_val_preds[i-1], outside_val_preds[i][0], inside_preds[i-1]], dtype=\"object\").reshape(1, -1)\n",
    "            pred = self.predict(input)\n",
    "            inside_preds.append(pred)\n",
    "        return inside_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/datasets/historical.data\")\n",
    "df = df.sort_values(by=\"date\",ascending=True)\n",
    "df_inside = df.loc[df[\"label\"] == \"inside\"].drop([\"label\"], axis=1)\n",
    "df_outside = df.loc[df[\"label\"] == \"outside\"].drop([\"label\"], axis=1)\n",
    "inside_arr=np.array(df_inside)\n",
    "outside_arr=np.array(df_outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 -> Outside Temperature Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_train, outside_test, outside_ivs = split_data(outside_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Wanted Predictions: 5.0\n"
     ]
    }
   ],
   "source": [
    "per_min = (2*60) + 30\n",
    "per_30_mins = per_min / 30\n",
    "\n",
    "print(\"Number of Wanted Predictions: \" + str(per_30_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = outside_train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.0000215613\n"
     ]
    }
   ],
   "source": [
    "model.train(train_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = outside_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.737656]]\n",
      "10.78\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[0:49]))\n",
    "print(test_data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.812096]]\n",
      "10.58\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[1:50]))\n",
    "print(test_data[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.824025]]\n",
      "10.35\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[2:51]))\n",
    "print(test_data[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_window = 50\n",
    "\n",
    "test_inout_seq = []\n",
    "L = len(test_data)\n",
    "for i in range(L-test_window):\n",
    "    train_seq = test_data[i:i+test_window]\n",
    "    train_label = test_data[i+test_window:i+test_window+1]\n",
    "    test_inout_seq.append((train_seq ,train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = [ x for x, _ in test_inout_seq ]\n",
    "true_Y = [ y[0] for _, y in test_inout_seq ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = []\n",
    "for X in test_X:\n",
    "    Y = model.predict(X)[0]\n",
    "    pred_Y.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.9592687396444167\n",
      "The rmse is:  1.1444307181832196\n",
      "The Correlation Score is is: 0.9836 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  11.14809281539917\n",
      "The Mean Absolute Error is:  0.7564291050544436\n"
     ]
    }
   ],
   "source": [
    "printRegStatistics(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.278472]]\n",
      "12.66\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([test_data[1]])))\n",
    "print(test_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.98, 12.3, 12.66, ..., 14.822, 15.6, 16.289], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(np.array(test_data[0:49]))[0]\n",
    "pred_Y = list(pred_Y)\n",
    "\n",
    "test_X_stream = test_data[50:]\n",
    "_ix = 0\n",
    "for X in test_X_stream:\n",
    "    if _ix == len(test_X_stream) - 1:\n",
    "        break\n",
    "    Y = model.predict(np.array([X]))[0,0]\n",
    "    pred_Y.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "pred_Y = np.array(pred_Y)\n",
    "true_Y = test_data[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.9747749111592113\n",
      "The rmse is:  0.8317133807817854\n",
      "The Correlation Score is is: 0.9874 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  10.431982585906983\n",
      "The Mean Absolute Error is:  0.5514762293463369\n"
     ]
    }
   ],
   "source": [
    "printRegStatistics(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0001001226\n",
      "RVE 0.9747772659729601 -> hidden_layer_size '50' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000055385\n",
      "RVE 0.9747743420749971 -> hidden_layer_size '50' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000279706\n",
      "RVE 0.974776405808909 -> hidden_layer_size '50' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001242574\n",
      "RVE 0.9747814662230647 -> hidden_layer_size '100' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000008138\n",
      "RVE 0.9747752504410033 -> hidden_layer_size '100' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000191966\n",
      "RVE 0.9747699142794141 -> hidden_layer_size '100' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000268046\n",
      "RVE 0.9747730403548921 -> hidden_layer_size '150' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000000163\n",
      "RVE 0.9747727295893932 -> hidden_layer_size '150' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000093265\n",
      "RVE 0.9747771335109023 -> hidden_layer_size '150' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000323359\n",
      "RVE 0.9747816351413197 -> hidden_layer_size '200' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000611409\n",
      "RVE 0.9747808555595228 -> hidden_layer_size '200' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000023492\n",
      "RVE 0.9747753436725197 -> hidden_layer_size '200' ; num_layers '4'\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "truth = test_data[50:]\n",
    "\n",
    "hidden_layer_sizes = [50,100,150,200]\n",
    "nums_layers = [1,2,4]\n",
    "\n",
    "hyper_params = itertools.product(hidden_layer_sizes, nums_layers)\n",
    "\n",
    "for params in hyper_params:\n",
    "\n",
    "    hidden_layer_size, num_layers = params\n",
    "\n",
    "    model = LSTM(output_size=1, hidden_layer_size=hidden_layer_size, num_layers=num_layers).to(device)\n",
    "    model.train(train_data, epochs=1)\n",
    "    #model.eval()\n",
    "\n",
    "    preds = model.predict(np.array(test_data[0:49]))[0]\n",
    "    preds = list(preds)\n",
    "\n",
    "    _ix = 0\n",
    "    for X in test_data[50:]:\n",
    "        if _ix == len(test_data[50:]) - 1:\n",
    "            break\n",
    "        Y = model.predict(np.array([X]))[0,0]\n",
    "        preds.append(Y)\n",
    "        _ix+=1\n",
    "        \n",
    "\n",
    "    RVE = explained_variance_score(truth, preds)\n",
    "\n",
    "    result = {\"RVE\": RVE, \"hidden_layer_size\": hidden_layer_size, \"num_layers\": num_layers}\n",
    "    print(f\"RVE {RVE} -> hidden_layer_size '{hidden_layer_size}' ; num_layers '{num_layers}'\")\n",
    "    results.append(result)\n",
    "\n",
    "    # hls 200 - nl 1 - RVE 0.9747816351413197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With multiple inputs + outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0003430746\n",
      "RVE 0.9747811136729241 -> hidden_layer_size '50' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002447922\n",
      "RVE 0.9747796207311098 -> hidden_layer_size '50' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0003614936\n",
      "RVE 0.9747807494036066 -> hidden_layer_size '50' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0008355238\n",
      "RVE 0.9747748306945716 -> hidden_layer_size '100' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0004488731\n",
      "RVE 0.9747785924735314 -> hidden_layer_size '100' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001496843\n",
      "RVE 0.9747813178439919 -> hidden_layer_size '100' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000350967\n",
      "RVE 0.9747807698753959 -> hidden_layer_size '150' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001870407\n",
      "RVE 0.9747812800629767 -> hidden_layer_size '150' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002436671\n",
      "RVE 0.9747774788790655 -> hidden_layer_size '150' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0004602174\n",
      "RVE 0.974780746608952 -> hidden_layer_size '200' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001069583\n",
      "RVE 0.9747807379643247 -> hidden_layer_size '200' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000650820\n",
      "RVE 0.9747757318914865 -> hidden_layer_size '200' ; num_layers '4'\n"
     ]
    }
   ],
   "source": [
    "results_multilabel = []\n",
    "\n",
    "truth = test_data[50:]\n",
    "\n",
    "hidden_layer_sizes = [50,100,150,200]\n",
    "nums_layers = [1,2,4]\n",
    "\n",
    "hyper_params = itertools.product(hidden_layer_sizes, nums_layers)\n",
    "\n",
    "for params in hyper_params:\n",
    "\n",
    "    hidden_layer_size, num_layers = params\n",
    "\n",
    "    model = LSTM(output_size=5, hidden_layer_size=hidden_layer_size, num_layers=num_layers).to(device)\n",
    "    model.train(train_data, epochs=1)\n",
    "    #model.eval()\n",
    "\n",
    "    preds = model.predict(np.array(test_data[0:49]))[0]\n",
    "    preds = list(preds)\n",
    "\n",
    "    _ix = 0\n",
    "    for X in test_data[50:]:\n",
    "        if _ix == len(test_data[50:]) - 1:\n",
    "            break\n",
    "        Y = model.predict(np.array([X]))[0,0]\n",
    "        preds.append(Y)\n",
    "        _ix+=1\n",
    "        \n",
    "\n",
    "    RVE = explained_variance_score(truth, preds)\n",
    "\n",
    "    result = {\"RVE\": RVE, \"hidden_layer_size\": hidden_layer_size, \"num_layers\": num_layers}\n",
    "    print(f\"RVE {RVE} -> hidden_layer_size '{hidden_layer_size}' ; num_layers '{num_layers}'\")\n",
    "    results_multilabel.append(result)\n",
    "    \n",
    "    # hls 100 - nl 4 - RVE 0.9747813178439919"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivs_data = outside_ivs[:,1]\n",
    "truth = ivs_data[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   1 loss: 0.00122739\n",
      "epoch:  25 loss: 0.0042992551\n",
      "The RVE is:  0.9836861223507917\n",
      "The rmse is:  0.8151775415994958\n",
      "The Correlation Score is is: 0.9918 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  6.203763076782224\n",
      "The Mean Absolute Error is:  0.569096624291944\n"
     ]
    }
   ],
   "source": [
    "model_data = np.concatenate((train_data, test_data), axis=0)\n",
    "\n",
    "model = LSTM(output_size=4, hidden_layer_size=100, num_layers=4).to(device)\n",
    "#model.train(model_data, epochs=1)\n",
    "model.train(model_data, epochs=26)\n",
    "#model.train(model_data, epochs=200)\n",
    "\n",
    "ivs_data = outside_ivs[:,1]\n",
    "\n",
    "truth = ivs_data[50:]\n",
    "\n",
    "preds = model.predict(np.array(ivs_data[0:49]))[0]\n",
    "preds = list(preds)\n",
    "\n",
    "_ix = 0\n",
    "for X in ivs_data[50:]:\n",
    "    if _ix == len(ivs_data[50:]) - 1:\n",
    "        break\n",
    "    Y = model.predict(np.array([X]))[0,0]\n",
    "    preds.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "printRegStatistics(truth, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.717048]\n",
      " [14.006069]\n",
      " [14.587363]\n",
      " [15.422805]]\n",
      "[15.539 18.6 19.189 19.15]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([test_data[0:1000]])))\n",
    "print(test_data[1000:1000+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "with open(\"./outside_model/model_v3.1-pickle\",\"wb\") as o:\n",
    "    pickle.dump(model, o)\n",
    "model.set_device(\"cpu\")\n",
    "model.to(\"cpu\")\n",
    "#for ix in len(model.hidden_cell.to(\"cpu\")):\n",
    "#    model.hidden_cell\n",
    "model.hidden_cell = None\n",
    "with open(\"./outside_model/model_v3.1-torch\",\"wb\") as o:\n",
    "    torch.save(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open(\"./outside_model/model_v3.1-torch\",\"rb\") as o:\n",
    "    _model = torch.load(o, encoding='bytes')\n",
    "#with open(\"./outside_model/model_v3.1-pickle\",\"rb\") as o:\n",
    "#    _model = pickle.load(o)\n",
    "print(_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4862, 4812]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\models\\main.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     preds\u001b[39m.\u001b[39mappend(Y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     _ix\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m printRegStatistics(truth, preds)\n",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\models\\main.ipynb Cell 36\u001b[0m in \u001b[0;36mprintRegStatistics\u001b[1;34m(truth, preds)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprintRegStatistics\u001b[39m(truth, preds):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe RVE is: \u001b[39m\u001b[39m\"\u001b[39m, explained_variance_score(truth, preds))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe rmse is: \u001b[39m\u001b[39m\"\u001b[39m, mean_squared_error(truth, preds, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/models/main.ipynb#Y113sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     corr, pval \u001b[39m=\u001b[39m pearsonr(truth, preds)\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:762\u001b[0m, in \u001b[0;36mexplained_variance_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplained_variance_score\u001b[39m(\n\u001b[0;32m    660\u001b[0m     y_true,\n\u001b[0;32m    661\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    666\u001b[0m ):\n\u001b[0;32m    667\u001b[0m     \u001b[39m\"\"\"Explained variance regression score function.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \n\u001b[0;32m    669\u001b[0m \u001b[39m    Best possible score is 1.0, lower values are worse.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 762\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    763\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    764\u001b[0m     )\n\u001b[0;32m    765\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    767\u001b[0m     y_diff_avg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage(y_true \u001b[39m-\u001b[39m y_pred, weights\u001b[39m=\u001b[39msample_weight, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4862, 4812]"
     ]
    }
   ],
   "source": [
    "preds = _model.predict(np.array(ivs_data[0:49]))[0]\n",
    "preds = list(preds)\n",
    "\n",
    "_ix = 0\n",
    "for X in ivs_data[50:]:\n",
    "    if _ix == len(ivs_data[50:]) - 1:\n",
    "        break\n",
    "    Y = _model.predict(np.array([X]))[0,0]\n",
    "    preds.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "printRegStatistics(truth, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inside Predictions Model\n",
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outside_val_curr_l</th>\n",
       "      <th>outside_val_valpred_l</th>\n",
       "      <th>outside_val_valpred_2</th>\n",
       "      <th>outside_val_valpred_3</th>\n",
       "      <th>outside_val_valpred_4</th>\n",
       "      <th>inside_val_curr_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.430</td>\n",
       "      <td>9.760</td>\n",
       "      <td>8.990</td>\n",
       "      <td>8.200</td>\n",
       "      <td>7.640</td>\n",
       "      <td>22.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.760</td>\n",
       "      <td>8.990</td>\n",
       "      <td>8.200</td>\n",
       "      <td>7.640</td>\n",
       "      <td>7.200</td>\n",
       "      <td>22.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.990</td>\n",
       "      <td>8.200</td>\n",
       "      <td>7.640</td>\n",
       "      <td>7.200</td>\n",
       "      <td>6.990</td>\n",
       "      <td>23.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.200</td>\n",
       "      <td>7.640</td>\n",
       "      <td>7.200</td>\n",
       "      <td>6.990</td>\n",
       "      <td>6.430</td>\n",
       "      <td>23.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.640</td>\n",
       "      <td>7.200</td>\n",
       "      <td>6.990</td>\n",
       "      <td>6.430</td>\n",
       "      <td>6.220</td>\n",
       "      <td>23.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48614</th>\n",
       "      <td>15.117</td>\n",
       "      <td>15.606</td>\n",
       "      <td>15.406</td>\n",
       "      <td>16.228</td>\n",
       "      <td>16.483</td>\n",
       "      <td>24.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48615</th>\n",
       "      <td>15.606</td>\n",
       "      <td>15.406</td>\n",
       "      <td>16.228</td>\n",
       "      <td>16.483</td>\n",
       "      <td>16.561</td>\n",
       "      <td>24.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48616</th>\n",
       "      <td>15.406</td>\n",
       "      <td>16.228</td>\n",
       "      <td>16.483</td>\n",
       "      <td>16.561</td>\n",
       "      <td>16.983</td>\n",
       "      <td>24.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48617</th>\n",
       "      <td>16.228</td>\n",
       "      <td>16.483</td>\n",
       "      <td>16.561</td>\n",
       "      <td>16.983</td>\n",
       "      <td>17.461</td>\n",
       "      <td>24.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48618</th>\n",
       "      <td>16.483</td>\n",
       "      <td>16.561</td>\n",
       "      <td>16.983</td>\n",
       "      <td>17.461</td>\n",
       "      <td>16.478</td>\n",
       "      <td>24.812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48619 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       outside_val_curr_l  outside_val_valpred_l  outside_val_valpred_2  \\\n",
       "0                  10.430                  9.760                  8.990   \n",
       "1                   9.760                  8.990                  8.200   \n",
       "2                   8.990                  8.200                  7.640   \n",
       "3                   8.200                  7.640                  7.200   \n",
       "4                   7.640                  7.200                  6.990   \n",
       "...                   ...                    ...                    ...   \n",
       "48614              15.117                 15.606                 15.406   \n",
       "48615              15.606                 15.406                 16.228   \n",
       "48616              15.406                 16.228                 16.483   \n",
       "48617              16.228                 16.483                 16.561   \n",
       "48618              16.483                 16.561                 16.983   \n",
       "\n",
       "       outside_val_valpred_3  outside_val_valpred_4  inside_val_curr_l  \n",
       "0                      8.200                  7.640             22.875  \n",
       "1                      7.640                  7.200             22.937  \n",
       "2                      7.200                  6.990             23.062  \n",
       "3                      6.990                  6.430             23.125  \n",
       "4                      6.430                  6.220             23.187  \n",
       "...                      ...                    ...                ...  \n",
       "48614                 16.228                 16.483             24.062  \n",
       "48615                 16.483                 16.561             24.125  \n",
       "48616                 16.561                 16.983             24.437  \n",
       "48617                 16.983                 17.461             24.500  \n",
       "48618                 17.461                 16.478             24.812  \n",
       "\n",
       "[48619 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outside_arr\n",
    "inside_arr\n",
    "\n",
    "outside_val_curr_l = []\n",
    "outside_val_valpred_l = []\n",
    "outside_val_valpred_2 = []\n",
    "outside_val_valpred_3 = []\n",
    "outside_val_valpred_4 = []\n",
    "\n",
    "inside_val_curr_l = []\n",
    "y = []\n",
    "\n",
    "assert outside_arr.size == inside_arr.size\n",
    "\n",
    "labels = [\"outside_val_curr_l\",\"outside_val_valpred_l\",\"outside_val_valpred_2\",\"outside_val_valpred_3\",\"outside_val_valpred_4\",\"inside_val_curr_l\"]\n",
    "\n",
    "for i in range(4,len(outside_arr)):\n",
    "    outside_val_valpred_4.append(outside_arr[i][1])\n",
    "    outside_val_valpred_3.append(outside_arr[i-1][1])\n",
    "    outside_val_valpred_2.append(outside_arr[i-2][1])\n",
    "    outside_val_valpred_l.append(outside_arr[i-3][1])\n",
    "    outside_val_curr_l.append(outside_arr[i-4][1])\n",
    "\n",
    "    inside_val_curr_l.append(inside_arr[i-4][1])\n",
    "\n",
    "    y.append([inside_arr[i-3][1], inside_arr[i-2][1], inside_arr[i-1][1], inside_arr[i][1]])\n",
    "\n",
    "df_arr = [ [outside_val_curr_l[i],outside_val_valpred_l[i],outside_val_valpred_2[i],outside_val_valpred_3[i],outside_val_valpred_4[i],inside_val_curr_l[i]] for i in range(len(inside_val_curr_l)) ]\n",
    "\n",
    "inside_X_train, inside_X_test, inside_X_ivs = split_data(np.array(df_arr))\n",
    "inside_y_train, inside_y_test, inside_y_ivs = split_data(np.array(y))\n",
    "\n",
    "df_inside_X_train = pd.DataFrame(inside_X_train, columns=labels)\n",
    "df_inside_X_test = pd.DataFrame(inside_X_test, columns=labels)\n",
    "df_inside_X_ivs = pd.DataFrame(inside_X_ivs, columns=labels)\n",
    "\n",
    "df = pd.DataFrame(df_arr, columns=labels)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.844591688876241\n",
      "The rmse is:  0.18992293768609675\n",
      "The Correlation Score is is: 0.9243 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  2.293232933697709\n",
      "The Mean Absolute Error is:  0.14036057314163217\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators = 100)\n",
    "rf_model.fit(df_inside_X_train, inside_y_train)\n",
    "\n",
    "preds = rf_model.predict(df_inside_X_test).flatten()\n",
    "truths = inside_y_test.flatten()\n",
    "\n",
    "printRegStatistics(preds,truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=RandomForestRegressor())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=RandomForestRegressor())"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/feature-selection-using-random-forest-26d7b747597f\n",
    "sel = SelectFromModel(RandomForestRegressor(n_estimators = 100))#, max_features=12) # when no max_features are specified, seems to vary between 12 and 15\n",
    "sel.fit(df_inside_X_train, inside_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False  True]\n",
      "1\n",
      "Index(['inside_val_curr_l'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sel.get_support())\n",
    "selected_feat= df_inside_X_train.columns[(sel.get_support())]\n",
    "print(len(selected_feat))\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       inside_val_curr_l\n",
      "0                 22.875\n",
      "1                 22.937\n",
      "2                 23.062\n",
      "3                 23.125\n",
      "4                 23.187\n",
      "...                  ...\n",
      "38890             23.312\n",
      "38891             23.375\n",
      "38892             23.500\n",
      "38893             23.375\n",
      "38894             23.500\n",
      "\n",
      "[38895 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_inside_X_train = df_inside_X_train[df_inside_X_train.columns[(sel.get_support())]]\n",
    "df_inside_X_test = df_inside_X_test[df_inside_X_test.columns[(sel.get_support())]]\n",
    "\n",
    "print(df_inside_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.8456982653069713\n",
      "The rmse is:  0.1861762414605077\n",
      "The Correlation Score is is: 0.9275 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  2.6192463235805796\n",
      "The Mean Absolute Error is:  0.13801686278670214\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 100)\n",
    "model.fit(df_inside_X_train.to_numpy(), inside_y_train)\n",
    "\n",
    "preds = model.predict(df_inside_X_test.to_numpy()).flatten()\n",
    "truths = inside_y_test.flatten()\n",
    "\n",
    "printRegStatistics(preds,truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.55185153 23.55528567 23.553122   23.54535476]]\n",
      "[23.437 23.562 23.625 23.437]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([df_inside_X_test.to_numpy()[0]]))\n",
    "print(p)\n",
    "print(inside_y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/inside_model/model_v1\",\"wb\") as o:\n",
    "    pickle.dump(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "The RVE is:  0.8456982653069713\n",
      "The rmse is:  0.1861762414605077\n",
      "The Correlation Score is is: 0.9275 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  2.6192463235805796\n",
      "The Mean Absolute Error is:  0.13801686278670214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"./models/inside_model/model_v1\",\"rb\") as o:\n",
    "    model = pickle.load(o, encoding='bytes')\n",
    "print(model)\n",
    "preds = model.predict(df_inside_X_test).flatten()\n",
    "truths = inside_y_test.flatten()\n",
    "\n",
    "printRegStatistics(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outside_val_curr_l</th>\n",
       "      <th>outside_val_valpred_l</th>\n",
       "      <th>inside_val_curr_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.430</td>\n",
       "      <td>9.760</td>\n",
       "      <td>22.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.760</td>\n",
       "      <td>8.990</td>\n",
       "      <td>22.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.990</td>\n",
       "      <td>8.200</td>\n",
       "      <td>23.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.200</td>\n",
       "      <td>7.640</td>\n",
       "      <td>23.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.640</td>\n",
       "      <td>7.200</td>\n",
       "      <td>23.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48617</th>\n",
       "      <td>16.228</td>\n",
       "      <td>16.483</td>\n",
       "      <td>24.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48618</th>\n",
       "      <td>16.483</td>\n",
       "      <td>16.561</td>\n",
       "      <td>24.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48619</th>\n",
       "      <td>16.561</td>\n",
       "      <td>16.983</td>\n",
       "      <td>24.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48620</th>\n",
       "      <td>16.983</td>\n",
       "      <td>17.461</td>\n",
       "      <td>24.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621</th>\n",
       "      <td>17.461</td>\n",
       "      <td>16.478</td>\n",
       "      <td>24.437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48622 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       outside_val_curr_l  outside_val_valpred_l  inside_val_curr_l\n",
       "0                  10.430                  9.760             22.875\n",
       "1                   9.760                  8.990             22.937\n",
       "2                   8.990                  8.200             23.062\n",
       "3                   8.200                  7.640             23.125\n",
       "4                   7.640                  7.200             23.187\n",
       "...                   ...                    ...                ...\n",
       "48617              16.228                 16.483             24.500\n",
       "48618              16.483                 16.561             24.812\n",
       "48619              16.561                 16.983             24.750\n",
       "48620              16.983                 17.461             24.500\n",
       "48621              17.461                 16.478             24.437\n",
       "\n",
       "[48622 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outside_arr\n",
    "inside_arr\n",
    "\n",
    "outside_val_curr_l = []\n",
    "outside_val_valpred_l = []\n",
    "\n",
    "inside_val_curr_l = []\n",
    "\n",
    "y = []\n",
    "\n",
    "assert outside_arr.size == inside_arr.size\n",
    "\n",
    "labels = [\"outside_val_curr_l\",\"outside_val_valpred_l\",\"inside_val_curr_l\"]\n",
    "\n",
    "for i in range(1,len(outside_arr)):\n",
    "    outside_val_valpred_l.append(outside_arr[i][1])\n",
    "    outside_val_curr_l.append(outside_arr[i-1][1])\n",
    "\n",
    "    inside_val_curr_l.append(inside_arr[i-1][1])\n",
    "\n",
    "    y.append(inside_arr[i][1])\n",
    "\n",
    "df_arr = [ [outside_val_curr_l[i],outside_val_valpred_l[i],inside_val_curr_l[i]] for i in range(len(inside_val_curr_l)) ]\n",
    "\n",
    "inside_X_train, inside_X_test, inside_X_ivs = split_data(np.array(df_arr))\n",
    "\n",
    "y = np.array(y)\n",
    "total_len=y.size\n",
    "\n",
    "train_p = 0.80\n",
    "test_p = 0.10\n",
    "ivs_p = 0.10\n",
    "\n",
    "train_len = round(total_len*train_p)\n",
    "test_len = round(total_len*test_p)\n",
    "ivs_len = round(total_len*ivs_p)\n",
    "\n",
    "model_len = train_len+test_len\n",
    "\n",
    "total_used_len = model_len+ivs_len\n",
    "\n",
    "inside_y_train = y[:train_len]\n",
    "inside_y_test = y[train_len:model_len]\n",
    "inside_y_ivs = y[model_len:total_used_len]\n",
    "\n",
    "df_inside_X_train = pd.DataFrame(inside_X_train, columns=labels)\n",
    "df_inside_X_test = pd.DataFrame(inside_X_test, columns=labels)\n",
    "df_inside_X_ivs = pd.DataFrame(inside_X_ivs, columns=labels)\n",
    "\n",
    "df = pd.DataFrame(df_arr, columns=labels)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.8947976157964002\n",
      "The rmse is:  0.15917090582348375\n",
      "The Correlation Score is is: 0.9476 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  1.2784524685074814\n",
      "The Mean Absolute Error is:  0.12196035073999228\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 100)\n",
    "model.fit(df_inside_X_train.to_numpy(), inside_y_train)\n",
    "\n",
    "preds = model.predict(df_inside_X_test.to_numpy()).flatten()\n",
    "truths = inside_y_test.flatten()\n",
    "\n",
    "printRegStatistics(preds,truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.54857]\n",
      "23.437\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([df_inside_X_test.to_numpy()[0]]))\n",
    "print(p)\n",
    "print(inside_y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/inside_model/model_v2\",\"wb\") as o:\n",
    "    pickle.dump(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor()\n",
      "The RVE is:  0.8947976157964002\n",
      "The rmse is:  0.15917090582348375\n",
      "The Correlation Score is is: 0.9476 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  1.2784524685074814\n",
      "The Mean Absolute Error is:  0.12196035073999228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rapos\\miniconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(\"./models/inside_model/model_v2\",\"rb\") as o:\n",
    "    model = pickle.load(o, encoding='bytes')\n",
    "print(model)\n",
    "preds = model.predict(df_inside_X_test).flatten()\n",
    "truths = inside_y_test.flatten()\n",
    "\n",
    "printRegStatistics(preds,truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.8947175926706176\n",
      "The rmse is:  0.15920844237402698\n",
      "The Correlation Score is is: 0.9475 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  1.3059624685074809\n",
      "The Mean Absolute Error is:  0.12173446103777685\n"
     ]
    }
   ],
   "source": [
    "inside_model = CustomRandomForestRegressor(n_preds = 4, n_estimators = 100)\n",
    "inside_model.fit(df_inside_X_train.to_numpy(), inside_y_train)\n",
    "\n",
    "preds = inside_model.predict(df_inside_X_test.to_numpy()).flatten()\n",
    "truths = inside_y_test.flatten()\n",
    "\n",
    "printRegStatistics(preds,truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./models/inside_model/model_v3\",\"wb\") as o:\n",
    "    pickle.dump(inside_model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=4, bias=True)\n",
      ")\n",
      "CustomRandomForestRegressor()\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "with open(\"./outside_model/model_v3\",\"rb\") as o:\n",
    "    outside_model: LSTM = torch.load(o, encoding='bytes')\n",
    "print(outside_model)\n",
    "with open(\"./inside_model/model_v3\",\"rb\") as o:\n",
    "    inside_model: CustomRandomForestRegressor = pickle.load(o, encoding='bytes')\n",
    "print(inside_model)\n",
    "\n",
    "\n",
    "outside_model.set_device()\n",
    "outside_model.predict(np.array(test_X_stream[0:1000]))\n",
    "\n",
    "\n",
    "outside_preds_total = []\n",
    "inside_preds_total = []\n",
    "\n",
    "assert len(test_X_stream) == len(true_Y)\n",
    "assert len(df_inside_X_test.to_numpy()) == len(inside_y_test)\n",
    "\n",
    "for i in range(1000,len(test_X_stream)):\n",
    "    outside_preds = outside_model.predict(np.array(test_X_stream[i]))\n",
    "    inside_preds = inside_model.total_predict(test_X_stream[i], outside_preds, inside_arr[i][1])\n",
    "\n",
    "    outside_preds = [ o[0] for o in outside_preds ]\n",
    "    inside_preds = [ o[0] for o in inside_preds ]\n",
    "\n",
    "    outside_preds_total.append(outside_preds)\n",
    "    inside_preds_total.append(inside_preds)\n",
    "\n",
    "\n",
    "outside_truth = []\n",
    "inside_truth = []\n",
    "\n",
    "for i in range(1005,true_Y.size):\n",
    "    outside_truth.append([true_Y[i-3], true_Y[i-2], true_Y[i-1], true_Y[i]])\n",
    "    inside_truth.append([inside_y_test[i-3], inside_y_test[i-2], inside_y_test[i-1], inside_y_test[i]])\n",
    "\n",
    "\n",
    "#print(\"Preds\")\n",
    "#print(outside_preds_total)\n",
    "#print(inside_preds_total)\n",
    "\n",
    "#print(\"Truth\")\n",
    "#print(outside_truth)\n",
    "#print(inside_truth)\n",
    "\n",
    "#print(\"Outside\")\n",
    "#printRegStatistics(outside_preds_total,outside_truth)\n",
    "#print(\"Inside\")\n",
    "#printRegStatistics(inside_preds_total,inside_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.914384, 10.945582, 10.9903, 11.040925]\n",
      "[22.894129999999972, 22.913012597732212, 22.85561683832897, 23.013715461919652]\n"
     ]
    }
   ],
   "source": [
    "outside_preds = outside_model.predict(np.array(test_X_stream[0]))\n",
    "inside_preds = inside_model.total_predict(test_X_stream[0], outside_preds, inside_arr[0][1])\n",
    "\n",
    "outside_preds = [ o[0] for o in outside_preds ]\n",
    "inside_preds = [ o[0] for o in inside_preds ]\n",
    "\n",
    "print(outside_preds)\n",
    "print(inside_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.875\n"
     ]
    }
   ],
   "source": [
    "print(inside_arr[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
