{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "torch.manual_seed(99)\n",
    "\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    output_size: int\n",
    "\n",
    "    hidden_layer_size: int\n",
    "    lstm: nn.LSTM\n",
    "    linear: nn.Linear\n",
    "    hidden_cell: tuple[torch.Tensor, torch.Tensor]\n",
    "    scaler: MinMaxScaler\n",
    "    device: str\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def predict(self, input):\n",
    "        X = self.scaler.fit_transform(input.reshape(-1, 1))\n",
    "        X = seq = torch.FloatTensor(X).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            self.hidden = (torch.zeros(1, 1, self.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size))\n",
    "            preds = self(X)\n",
    "            Y = np.array(preds.cpu())\n",
    "        actual_predictions = self.scaler.inverse_transform(Y.reshape(-1, 1))\n",
    "        return actual_predictions\n",
    "\n",
    "    def set_device(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "        \n",
    "        self.to(self.device)\n",
    "\n",
    "    def train(self, train_data, train_window = 50, epochs = 100):\n",
    "\n",
    "        # Initiate loss function and optimizer\n",
    "\n",
    "        loss_function = nn.MSELoss().to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        # Scale\n",
    "        \n",
    "        train_data_normalized = self.scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "        train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1).to(self.device)\n",
    "\n",
    "        # Create sequences\n",
    "        \n",
    "        train_inout_seq = []\n",
    "        L = len(train_data_normalized)\n",
    "        for i in range(L-train_window):\n",
    "            train_seq = train_data_normalized[i:i+train_window]\n",
    "            # TODO - offset on the start for direct decoding with several (5) of these models giving (5) concurrent predictions?\n",
    "            train_label = train_data_normalized[i+train_window:i+train_window+self.output_size]\n",
    "            train_inout_seq.append((train_seq ,train_label))\n",
    "        \n",
    "        # Train the model\n",
    "\n",
    "        for i in range(epochs):\n",
    "            _ix = -1\n",
    "            for seq, labels in train_inout_seq:\n",
    "                seq = seq.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                if len(labels) != self.output_size:\n",
    "                    continue\n",
    "\n",
    "                _ix +=1\n",
    "                \n",
    "                #if torch.isnan(seq).any().item():\n",
    "                #    print(f\"nan values in seq at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                #if pd.isna(labels.item()):\n",
    "                #    print(f\"nan labels at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                                torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                #if pd.isna(y_pred.item()):\n",
    "                #    print(f\"nan preds at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                single_loss = loss_function(y_pred, labels)\n",
    "                #if pd.isna(single_loss.item()):\n",
    "                #    print(f\"nan loss at {_ix}\")\n",
    "                #    raise\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if i%25 == 1:\n",
    "                print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "        # Finalize\n",
    "        #self.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/datasets/historical.data\")\n",
    "df = df.sort_values(by=\"date\",ascending=True)\n",
    "df_inside = df.loc[df[\"label\"] == \"inside\"].drop([\"label\"], axis=1)\n",
    "df_outside = df.loc[df[\"label\"] == \"outside\"].drop([\"label\"], axis=1)\n",
    "inside_arr=np.array(df_inside)\n",
    "outside_arr=np.array(df_outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(arr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    total_len,_=arr.shape\n",
    "\n",
    "    train_p = 0.80\n",
    "    test_p = 0.10\n",
    "    ivs_p = 0.10\n",
    "\n",
    "    train_len = round(total_len*train_p)\n",
    "    test_len = round(total_len*test_p)\n",
    "    ivs_len = round(total_len*ivs_p)\n",
    "\n",
    "    model_len = train_len+test_len\n",
    "\n",
    "    total_used_len = model_len+ivs_len\n",
    "\n",
    "    train = arr[:train_len]\n",
    "    test = arr[train_len:model_len]\n",
    "    ivs = arr[model_len:total_used_len]\n",
    "\n",
    "    return train, test, ivs\n",
    "\n",
    "\n",
    "inside_train, inside_test, inside_ivs = split_data(inside_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Wanted Predictions: 5.0\n"
     ]
    }
   ],
   "source": [
    "per_min = (2*60) + 30\n",
    "per_30_mins = per_min / 30\n",
    "\n",
    "print(\"Number of Wanted Predictions: \" + str(per_30_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = inside_train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.0002483580\n"
     ]
    }
   ],
   "source": [
    "model.train(train_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = inside_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.494268]]\n",
      "23.375\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[0:49]))\n",
    "print(test_data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.527887]]\n",
      "23.437\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[1:50]))\n",
    "print(test_data[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.507456]]\n",
      "23.312\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[2:51]))\n",
    "print(test_data[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_window = 50\n",
    "\n",
    "test_inout_seq = []\n",
    "L = len(test_data)\n",
    "for i in range(L-test_window):\n",
    "    train_seq = test_data[i:i+test_window]\n",
    "    train_label = test_data[i+test_window:i+test_window+1]\n",
    "    test_inout_seq.append((train_seq ,train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRegStatistics(truth, preds):\n",
    "    print(\"The RVE is: \", explained_variance_score(truth, preds))\n",
    "    print(\"The rmse is: \", mean_squared_error(truth, preds, squared=False))\n",
    "    corr, pval = pearsonr(truth, preds)\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "    print(\"The Maximum Error is is: \", max_error(truth, preds))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(truth, preds))\n",
    "\n",
    "test_X = [ x for x, _ in test_inout_seq ]\n",
    "true_Y = [ y[0] for _, y in test_inout_seq ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = []\n",
    "for X in test_X:\n",
    "    Y = model.predict(X)[0]\n",
    "    pred_Y.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.8978764419591279\n",
      "The rmse is:  0.1934079703350684\n",
      "The Correlation Score is is: 0.9481 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  1.2700949361588663\n",
      "The Mean Absolute Error is:  0.15038657969655386\n"
     ]
    }
   ],
   "source": [
    "printRegStatistics(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.774408]]\n",
      "23.562\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([test_data[1]])))\n",
    "print(test_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.625, 23.437, 23.562, ..., 24.0, 24.312, 24.625], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(np.array(test_data[0:49]))[0]\n",
    "pred_Y = list(pred_Y)\n",
    "\n",
    "test_X_stream = test_data[50:]\n",
    "_ix = 0\n",
    "for X in test_X_stream:\n",
    "    if _ix == len(test_X_stream) - 1:\n",
    "        break\n",
    "    Y = model.predict(np.array([X]))[0,0]\n",
    "    pred_Y.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "pred_Y = np.array(pred_Y)\n",
    "true_Y = test_data[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.9215021944542544\n",
      "The rmse is:  0.3666193784647493\n",
      "The Correlation Score is is: 0.9608 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  1.650580470826835\n",
      "The Mean Absolute Error is:  0.3415378658962491\n"
     ]
    }
   ],
   "source": [
    "printRegStatistics(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0001781297\n",
      "RVE 0.9215223812215173 -> hidden_layer_size '50' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0009761230\n",
      "RVE 0.9215358010995972 -> hidden_layer_size '50' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0005194269\n",
      "RVE 0.9214689878168127 -> hidden_layer_size '50' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001543104\n",
      "RVE 0.9214912420035739 -> hidden_layer_size '100' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002654023\n",
      "RVE 0.9215121020220935 -> hidden_layer_size '100' ; num_layers '2'\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "truth = test_data[50:]\n",
    "\n",
    "hidden_layer_sizes = [50,100,150,200]\n",
    "nums_layers = [1,2,4]\n",
    "\n",
    "hyper_params = itertools.product(hidden_layer_sizes, nums_layers)\n",
    "\n",
    "for params in hyper_params:\n",
    "\n",
    "    hidden_layer_size, num_layers = params\n",
    "\n",
    "    model = LSTM(output_size=1, hidden_layer_size=hidden_layer_size, num_layers=num_layers).to(device)\n",
    "    model.train(train_data, epochs=1)\n",
    "    #model.eval()\n",
    "\n",
    "    preds = model.predict(np.array(test_data[0:49]))[0]\n",
    "    preds = list(preds)\n",
    "\n",
    "    _ix = 0\n",
    "    for X in test_data[50:]:\n",
    "        if _ix == len(test_data[50:]) - 1:\n",
    "            break\n",
    "        Y = model.predict(np.array([X]))[0,0]\n",
    "        preds.append(Y)\n",
    "        _ix+=1\n",
    "        \n",
    "\n",
    "    RVE = explained_variance_score(truth, preds)\n",
    "\n",
    "    result = {\"RVE\": RVE, \"hidden_layer_size\": hidden_layer_size, \"num_layers\": num_layers}\n",
    "    print(f\"RVE {RVE} -> hidden_layer_size '{hidden_layer_size}' ; num_layers '{num_layers}'\")\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With multiple inputs + outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0002558756\n",
      "RVE 0.921498742817958 -> hidden_layer_size '50' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002800011\n",
      "RVE 0.9214869960509349 -> hidden_layer_size '50' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002937584\n",
      "RVE 0.9215082573693888 -> hidden_layer_size '50' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002748164\n",
      "RVE 0.9215243618004502 -> hidden_layer_size '100' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002635954\n",
      "RVE 0.9214884668787288 -> hidden_layer_size '100' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002857487\n",
      "RVE 0.9215238905097296 -> hidden_layer_size '100' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002695488\n",
      "RVE 0.9214833783721603 -> hidden_layer_size '150' ; num_layers '1'\n",
      "cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\main.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m hidden_layer_size, num_layers \u001b[39m=\u001b[39m params\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model \u001b[39m=\u001b[39m LSTM(output_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, hidden_layer_size\u001b[39m=\u001b[39mhidden_layer_size, num_layers\u001b[39m=\u001b[39mnum_layers)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(train_data, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#model.eval()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray(test_data[\u001b[39m0\u001b[39m:\u001b[39m49\u001b[39m]))[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\main.ipynb Cell 26\u001b[0m in \u001b[0;36mLSTM.train\u001b[1;34m(self, train_data, train_window, epochs)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m     single_loss \u001b[39m=\u001b[39m loss_function(y_pred, labels)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39m#if pd.isna(single_loss.item()):\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m     \u001b[39m#    print(f\"nan loss at {_ix}\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     \u001b[39m#    raise\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m     single_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X40sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m25\u001b[39m \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_multilabel = []\n",
    "\n",
    "truth = test_data[50:]\n",
    "\n",
    "hidden_layer_sizes = [50,100,150,200]\n",
    "nums_layers = [1,2,4]\n",
    "\n",
    "hyper_params = itertools.product(hidden_layer_sizes, nums_layers)\n",
    "\n",
    "for params in hyper_params:\n",
    "\n",
    "    hidden_layer_size, num_layers = params\n",
    "\n",
    "    model = LSTM(output_size=5, hidden_layer_size=hidden_layer_size, num_layers=num_layers).to(device)\n",
    "    model.train(train_data, epochs=1)\n",
    "    #model.eval()\n",
    "\n",
    "    preds = model.predict(np.array(test_data[0:49]))[0]\n",
    "    preds = list(preds)\n",
    "\n",
    "    _ix = 0\n",
    "    for X in test_data[50:]:\n",
    "        if _ix == len(test_data[50:]) - 1:\n",
    "            break\n",
    "        Y = model.predict(np.array([X]))[0,0]\n",
    "        preds.append(Y)\n",
    "        _ix+=1\n",
    "        \n",
    "\n",
    "    RVE = explained_variance_score(truth, preds)\n",
    "\n",
    "    result = {\"RVE\": RVE, \"hidden_layer_size\": hidden_layer_size, \"num_layers\": num_layers}\n",
    "    print(f\"RVE {RVE} -> hidden_layer_size '{hidden_layer_size}' ; num_layers '{num_layers}'\")\n",
    "    results_multilabel.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0030084946\n",
      "The RVE is:  0.96185821931108\n",
      "The rmse is:  0.4760790154040653\n",
      "The Correlation Score is is: 0.9809 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  1.5147955780029285\n",
      "The Mean Absolute Error is:  0.4513923426666713\n"
     ]
    }
   ],
   "source": [
    "model_data = np.concatenate((train_data, test_data), axis=0)\n",
    "\n",
    "model = LSTM(output_size=5, hidden_layer_size=100, num_layers=1).to(device)\n",
    "#model.train(model_data, epochs=1)\n",
    "model.train(model_data, epochs=200)\n",
    "\n",
    "ivs_data = inside_ivs[:,1]\n",
    "\n",
    "truth = ivs_data[50:]\n",
    "\n",
    "preds = model.predict(np.array(ivs_data[0:49]))[0]\n",
    "preds = list(preds)\n",
    "\n",
    "_ix = 0\n",
    "for X in ivs_data[50:]:\n",
    "    if _ix == len(ivs_data[50:]) - 1:\n",
    "        break\n",
    "    Y = model.predict(np.array([X]))[0,0]\n",
    "    preds.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "printRegStatistics(truth, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./model\",\"wb\") as o:\n",
    "    pickle.dump(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open(\"./model\",\"rb\") as o:\n",
    "    model = pickle.load(o, encoding='bytes')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
