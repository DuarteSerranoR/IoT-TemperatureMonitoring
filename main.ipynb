{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pickle\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "torch.manual_seed(99)\n",
    "\n",
    "from matplotlib import pyplot as plot\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    output_size: int\n",
    "\n",
    "    hidden_layer_size: int\n",
    "    lstm: nn.LSTM\n",
    "    linear: nn.Linear\n",
    "    hidden_cell: tuple[torch.Tensor, torch.Tensor]\n",
    "    scaler: MinMaxScaler\n",
    "    device: str\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "        self.scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def predict(self, input):\n",
    "        X = self.scaler.fit_transform(input.reshape(-1, 1))\n",
    "        X = seq = torch.FloatTensor(X).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            self.hidden = (torch.zeros(1, 1, self.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size))\n",
    "            preds = self(X)\n",
    "            Y = np.array(preds.cpu())\n",
    "        actual_predictions = self.scaler.inverse_transform(Y.reshape(-1, 1))\n",
    "        return actual_predictions\n",
    "\n",
    "    def set_device(self):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(self.device)\n",
    "        \n",
    "        self.to(self.device)\n",
    "\n",
    "    def train(self, train_data, train_window = 50, epochs = 100):\n",
    "\n",
    "        # Initiate loss function and optimizer\n",
    "\n",
    "        loss_function = nn.MSELoss().to(self.device)\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        # Scale\n",
    "        \n",
    "        train_data_normalized = self.scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "        train_data_normalized = torch.FloatTensor(train_data_normalized).view(-1).to(self.device)\n",
    "\n",
    "        # Create sequences\n",
    "        \n",
    "        train_inout_seq = []\n",
    "        L = len(train_data_normalized)\n",
    "        for i in range(L-train_window):\n",
    "            train_seq = train_data_normalized[i:i+train_window]\n",
    "            # TODO - offset on the start for direct decoding with several (5) of these models giving (5) concurrent predictions?\n",
    "            train_label = train_data_normalized[i+train_window:i+train_window+self.output_size]\n",
    "            train_inout_seq.append((train_seq ,train_label))\n",
    "        \n",
    "        # Train the model\n",
    "\n",
    "        for i in range(epochs):\n",
    "            _ix = -1\n",
    "            for seq, labels in train_inout_seq:\n",
    "                seq = seq.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                if len(labels) != self.output_size:\n",
    "                    continue\n",
    "\n",
    "                _ix +=1\n",
    "                \n",
    "                #if torch.isnan(seq).any().item():\n",
    "                #    print(f\"nan values in seq at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                #if pd.isna(labels.item()):\n",
    "                #    print(f\"nan labels at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                                torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "                y_pred = self(seq)\n",
    "                #if pd.isna(y_pred.item()):\n",
    "                #    print(f\"nan preds at {_ix}\")\n",
    "                #    continue\n",
    "\n",
    "                single_loss = loss_function(y_pred, labels)\n",
    "                #if pd.isna(single_loss.item()):\n",
    "                #    print(f\"nan loss at {_ix}\")\n",
    "                #    raise\n",
    "                single_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if i%25 == 1:\n",
    "                print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "\n",
    "        # Finalize\n",
    "        #self.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/datasets/historical.data\")\n",
    "df = df.sort_values(by=\"date\",ascending=True)\n",
    "df_inside = df.loc[df[\"label\"] == \"inside\"].drop([\"label\"], axis=1)\n",
    "df_outside = df.loc[df[\"label\"] == \"outside\"].drop([\"label\"], axis=1)\n",
    "inside_arr=np.array(df_inside)\n",
    "outside_arr=np.array(df_outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(arr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    total_len,_=arr.shape\n",
    "\n",
    "    train_p = 0.80\n",
    "    test_p = 0.10\n",
    "    ivs_p = 0.10\n",
    "\n",
    "    train_len = round(total_len*train_p)\n",
    "    test_len = round(total_len*test_p)\n",
    "    ivs_len = round(total_len*ivs_p)\n",
    "\n",
    "    model_len = train_len+test_len\n",
    "\n",
    "    total_used_len = model_len+ivs_len\n",
    "\n",
    "    train = arr[:train_len]\n",
    "    test = arr[train_len:model_len]\n",
    "    ivs = arr[model_len:total_used_len]\n",
    "\n",
    "    return train, test, ivs\n",
    "\n",
    "\n",
    "outside_train, outside_test, outside_ivs = split_data(outside_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Wanted Predictions: 5.0\n"
     ]
    }
   ],
   "source": [
    "per_min = (2*60) + 30\n",
    "per_30_mins = per_min / 30\n",
    "\n",
    "print(\"Number of Wanted Predictions: \" + str(per_30_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = outside_train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.0000215613\n"
     ]
    }
   ],
   "source": [
    "model.train(train_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = outside_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.737656]]\n",
      "10.78\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[0:49]))\n",
    "print(test_data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.812096]]\n",
      "10.58\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[1:50]))\n",
    "print(test_data[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.824025]]\n",
      "10.35\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(test_data[2:51]))\n",
    "print(test_data[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_window = 50\n",
    "\n",
    "test_inout_seq = []\n",
    "L = len(test_data)\n",
    "for i in range(L-test_window):\n",
    "    train_seq = test_data[i:i+test_window]\n",
    "    train_label = test_data[i+test_window:i+test_window+1]\n",
    "    test_inout_seq.append((train_seq ,train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRegStatistics(truth, preds):\n",
    "    print(\"The RVE is: \", explained_variance_score(truth, preds))\n",
    "    print(\"The rmse is: \", mean_squared_error(truth, preds, squared=False))\n",
    "    corr, pval = pearsonr(truth, preds)\n",
    "    print(\"The Correlation Score is is: %6.4f (p-value=%e)\\n\"%(corr,pval))\n",
    "    print(\"The Maximum Error is is: \", max_error(truth, preds))\n",
    "    print(\"The Mean Absolute Error is: \", mean_absolute_error(truth, preds))\n",
    "\n",
    "test_X = [ x for x, _ in test_inout_seq ]\n",
    "true_Y = [ y[0] for _, y in test_inout_seq ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = []\n",
    "for X in test_X:\n",
    "    Y = model.predict(X)[0]\n",
    "    pred_Y.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.9592687396444167\n",
      "The rmse is:  1.1444307181832196\n",
      "The Correlation Score is is: 0.9836 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  11.14809281539917\n",
      "The Mean Absolute Error is:  0.7564291050544436\n"
     ]
    }
   ],
   "source": [
    "printRegStatistics(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.278472]]\n",
      "12.66\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([test_data[1]])))\n",
    "print(test_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.98, 12.3, 12.66, ..., 14.822, 15.6, 16.289], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(np.array(test_data[0:49]))[0]\n",
    "pred_Y = list(pred_Y)\n",
    "\n",
    "test_X_stream = test_data[50:]\n",
    "_ix = 0\n",
    "for X in test_X_stream:\n",
    "    if _ix == len(test_X_stream) - 1:\n",
    "        break\n",
    "    Y = model.predict(np.array([X]))[0,0]\n",
    "    pred_Y.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "pred_Y = np.array(pred_Y)\n",
    "true_Y = test_data[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RVE is:  0.9747749111592113\n",
      "The rmse is:  0.8317133807817854\n",
      "The Correlation Score is is: 0.9874 (p-value=0.000000e+00)\n",
      "\n",
      "The Maximum Error is is:  10.431982585906983\n",
      "The Mean Absolute Error is:  0.5514762293463369\n"
     ]
    }
   ],
   "source": [
    "printRegStatistics(true_Y, pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0001001226\n",
      "RVE 0.9747772659729601 -> hidden_layer_size '50' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000055385\n",
      "RVE 0.9747743420749971 -> hidden_layer_size '50' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000279706\n",
      "RVE 0.974776405808909 -> hidden_layer_size '50' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001242574\n",
      "RVE 0.9747814662230647 -> hidden_layer_size '100' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000008138\n",
      "RVE 0.9747752504410033 -> hidden_layer_size '100' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000191966\n",
      "RVE 0.9747699142794141 -> hidden_layer_size '100' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000268046\n",
      "RVE 0.9747730403548921 -> hidden_layer_size '150' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000000163\n",
      "RVE 0.9747727295893932 -> hidden_layer_size '150' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000093265\n",
      "RVE 0.9747771335109023 -> hidden_layer_size '150' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000323359\n",
      "RVE 0.9747816351413197 -> hidden_layer_size '200' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000611409\n",
      "RVE 0.9747808555595228 -> hidden_layer_size '200' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000023492\n",
      "RVE 0.9747753436725197 -> hidden_layer_size '200' ; num_layers '4'\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "truth = test_data[50:]\n",
    "\n",
    "hidden_layer_sizes = [50,100,150,200]\n",
    "nums_layers = [1,2,4]\n",
    "\n",
    "hyper_params = itertools.product(hidden_layer_sizes, nums_layers)\n",
    "\n",
    "for params in hyper_params:\n",
    "\n",
    "    hidden_layer_size, num_layers = params\n",
    "\n",
    "    model = LSTM(output_size=1, hidden_layer_size=hidden_layer_size, num_layers=num_layers).to(device)\n",
    "    model.train(train_data, epochs=1)\n",
    "    #model.eval()\n",
    "\n",
    "    preds = model.predict(np.array(test_data[0:49]))[0]\n",
    "    preds = list(preds)\n",
    "\n",
    "    _ix = 0\n",
    "    for X in test_data[50:]:\n",
    "        if _ix == len(test_data[50:]) - 1:\n",
    "            break\n",
    "        Y = model.predict(np.array([X]))[0,0]\n",
    "        preds.append(Y)\n",
    "        _ix+=1\n",
    "        \n",
    "\n",
    "    RVE = explained_variance_score(truth, preds)\n",
    "\n",
    "    result = {\"RVE\": RVE, \"hidden_layer_size\": hidden_layer_size, \"num_layers\": num_layers}\n",
    "    print(f\"RVE {RVE} -> hidden_layer_size '{hidden_layer_size}' ; num_layers '{num_layers}'\")\n",
    "    results.append(result)\n",
    "\n",
    "    # hls 200 - nl 1 - RVE 0.9747816351413197"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With multiple inputs + outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   0 loss: 0.0003430746\n",
      "RVE 0.9747811136729241 -> hidden_layer_size '50' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002447922\n",
      "RVE 0.9747796207311098 -> hidden_layer_size '50' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0003614936\n",
      "RVE 0.9747807494036066 -> hidden_layer_size '50' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0008355238\n",
      "RVE 0.9747748306945716 -> hidden_layer_size '100' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0004488731\n",
      "RVE 0.9747785924735314 -> hidden_layer_size '100' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001496843\n",
      "RVE 0.9747813178439919 -> hidden_layer_size '100' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000350967\n",
      "RVE 0.9747807698753959 -> hidden_layer_size '150' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001870407\n",
      "RVE 0.9747812800629767 -> hidden_layer_size '150' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0002436671\n",
      "RVE 0.9747774788790655 -> hidden_layer_size '150' ; num_layers '4'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0004602174\n",
      "RVE 0.974780746608952 -> hidden_layer_size '200' ; num_layers '1'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0001069583\n",
      "RVE 0.9747807379643247 -> hidden_layer_size '200' ; num_layers '2'\n",
      "cuda\n",
      "epoch:   0 loss: 0.0000650820\n",
      "RVE 0.9747757318914865 -> hidden_layer_size '200' ; num_layers '4'\n"
     ]
    }
   ],
   "source": [
    "results_multilabel = []\n",
    "\n",
    "truth = test_data[50:]\n",
    "\n",
    "hidden_layer_sizes = [50,100,150,200]\n",
    "nums_layers = [1,2,4]\n",
    "\n",
    "hyper_params = itertools.product(hidden_layer_sizes, nums_layers)\n",
    "\n",
    "for params in hyper_params:\n",
    "\n",
    "    hidden_layer_size, num_layers = params\n",
    "\n",
    "    model = LSTM(output_size=5, hidden_layer_size=hidden_layer_size, num_layers=num_layers).to(device)\n",
    "    model.train(train_data, epochs=1)\n",
    "    #model.eval()\n",
    "\n",
    "    preds = model.predict(np.array(test_data[0:49]))[0]\n",
    "    preds = list(preds)\n",
    "\n",
    "    _ix = 0\n",
    "    for X in test_data[50:]:\n",
    "        if _ix == len(test_data[50:]) - 1:\n",
    "            break\n",
    "        Y = model.predict(np.array([X]))[0,0]\n",
    "        preds.append(Y)\n",
    "        _ix+=1\n",
    "        \n",
    "\n",
    "    RVE = explained_variance_score(truth, preds)\n",
    "\n",
    "    result = {\"RVE\": RVE, \"hidden_layer_size\": hidden_layer_size, \"num_layers\": num_layers}\n",
    "    print(f\"RVE {RVE} -> hidden_layer_size '{hidden_layer_size}' ; num_layers '{num_layers}'\")\n",
    "    results_multilabel.append(result)\n",
    "    \n",
    "    # hls 100 - nl 4 - RVE 0.9747813178439919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch:   1 loss: 0.00323140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\main.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m LSTM(output_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, hidden_layer_size\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m, num_layers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#model.train(model_data, epochs=1)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain(model_data, epochs\u001b[39m=\u001b[39;49m\u001b[39m26\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#model.train(model_data, epochs=200)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ivs_data \u001b[39m=\u001b[39m inside_ivs[:,\u001b[39m1\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\main.ipynb Cell 27\u001b[0m in \u001b[0;36mLSTM.train\u001b[1;34m(self, train_data, train_window, epochs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m _ix \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39m#if torch.isnan(seq).any().item():\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39m#    print(f\"nan values in seq at {_ix}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m#    continue\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m#    print(f\"nan labels at {_ix}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39m#    continue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_cell \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_layer_size)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m                 torch\u001b[39m.\u001b[39mzeros(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_layer_size)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X50sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(seq)\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\optim\\optimizer.py:237\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[1;34m(self, set_to_none)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m foreach:\n\u001b[0;32m    236\u001b[0m     per_device_and_dtype_grads \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m: defaultdict(\u001b[39mlist\u001b[39m))\n\u001b[1;32m--> 237\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_zero_grad_profile_name):\n\u001b[0;32m    238\u001b[0m     \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[0;32m    239\u001b[0m         \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m group[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\autograd\\profiler.py:446\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[0;32m    447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\_ops.py:143\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    139\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_data = np.concatenate((train_data, test_data), axis=0)\n",
    "\n",
    "model = LSTM(output_size=5, hidden_layer_size=100, num_layers=4).to(device)\n",
    "#model.train(model_data, epochs=1)\n",
    "model.train(model_data, epochs=26)\n",
    "#model.train(model_data, epochs=200)\n",
    "\n",
    "ivs_data = outside_ivs[:,1]\n",
    "\n",
    "truth = ivs_data[50:]\n",
    "\n",
    "preds = model.predict(np.array(ivs_data[0:49]))[0]\n",
    "preds = list(preds)\n",
    "\n",
    "_ix = 0\n",
    "for X in ivs_data[50:]:\n",
    "    if _ix == len(ivs_data[50:]) - 1:\n",
    "        break\n",
    "    Y = model.predict(np.array([X]))[0,0]\n",
    "    preds.append(Y)\n",
    "    _ix+=1\n",
    "\n",
    "printRegStatistics(truth, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./model\",\"wb\") as o:\n",
    "    pickle.dump(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(1, 100)\n",
      "  (linear): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with open(\"./model\",\"rb\") as o:\n",
    "    model = pickle.load(o, encoding='bytes')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
