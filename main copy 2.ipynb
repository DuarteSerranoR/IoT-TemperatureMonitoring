{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "torch.manual_seed(99)\n",
    "\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.875</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.937</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.062</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.125</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.187</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97001</th>\n",
       "      <td>24.812</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97002</th>\n",
       "      <td>24.750</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97005</th>\n",
       "      <td>24.500</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97007</th>\n",
       "      <td>24.437</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97009</th>\n",
       "      <td>24.562</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48387 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature  month  day  hour  minute\n",
       "1           22.875      1   21     0      30\n",
       "2           22.937      1   21     1       0\n",
       "4           23.062      1   21     1      30\n",
       "6           23.125      1   21     2       0\n",
       "8           23.187      1   21     2      30\n",
       "...            ...    ...  ...   ...     ...\n",
       "97001       24.812     10   29    21      30\n",
       "97002       24.750     10   29    22       0\n",
       "97005       24.500     10   29    22      30\n",
       "97007       24.437     10   29    23       0\n",
       "97009       24.562     10   29    23      30\n",
       "\n",
       "[48387 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/datasets/historical.data\")\n",
    "#df = df.set_index(\"date\").sort_index(ascending=True)\n",
    "df = df.sort_values(by=\"date\",ascending=True)\n",
    "df[\"month\"] = df.apply(lambda x: int(x[\"date\"].split(\"-\")[1])-1, axis=1) # category indexed to 0\n",
    "df[\"day\"] = df.apply(lambda x: int(x[\"date\"].split(\" \")[0].split(\"-\")[2])-1, axis=1) # category indexed to 0\n",
    "df[\"hour\"] = df.apply(lambda x: int(x[\"date\"].split(\" \")[1].split(\":\")[0]), axis=1)\n",
    "df[\"minute\"] = df.apply(lambda x: int(x[\"date\"].split(\" \")[1].split(\":\")[1]), axis=1)\n",
    "df = df.drop([\"date\"], axis=1)\n",
    "#df.apply(lambda x: x[\"date\"].split(\" \")[0].split(\"-\")[1] + \"-\" + x[\"date\"].split(\" \")[0].split(\"-\")[2], axis=1)\n",
    "#display(df)\n",
    "df_inside = df.loc[df[\"label\"] == \"inside\"].drop([\"label\"], axis=1)\n",
    "df_outside = df.loc[df[\"label\"] == \"outside\"].drop([\"label\"], axis=1)\n",
    "print(\"inside\")\n",
    "display(df_inside)\n",
    "#print(\"outside\")\n",
    "#display(df_outside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "[[22.875  1.    21.     0.    30.   ]\n",
      " [22.937  1.    21.     1.     0.   ]\n",
      " [23.062  1.    21.     1.    30.   ]\n",
      " ...\n",
      " [23.375  4.    12.     8.     0.   ]\n",
      " [23.437  4.    12.     8.    30.   ]\n",
      " [23.375  4.    12.     9.     0.   ]]\n",
      "test\n",
      "[[23.375  4.    12.     9.    30.   ]\n",
      " [23.437  4.    12.    10.     0.   ]\n",
      " [23.375  4.    12.    10.    30.   ]\n",
      " ...\n",
      " [25.125  7.    21.     3.    30.   ]\n",
      " [25.062  7.    21.     4.     0.   ]\n",
      " [25.062  7.    21.     4.    30.   ]]\n",
      "ivs\n",
      "[[25.125  7.    21.     5.     0.   ]\n",
      " [25.062  7.    21.     5.    30.   ]\n",
      " [25.125  7.    21.     6.     0.   ]\n",
      " ...\n",
      " [24.5   10.    29.    22.    30.   ]\n",
      " [24.437 10.    29.    23.     0.   ]\n",
      " [24.562 10.    29.    23.    30.   ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inside_arr=np.array(df_inside)\n",
    "outside_arr=np.array(df_outside)\n",
    "\n",
    "#print(inside_arr)\n",
    "\n",
    "#train_test_split(inside_arr, shuffle=False)\n",
    "\n",
    "def split_data(arr: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    total_len,_=arr.shape\n",
    "\n",
    "    train_p = 0.80\n",
    "    test_p = 0.10\n",
    "    ivs_p = 0.10\n",
    "\n",
    "    train_len = round(total_len*train_p)\n",
    "    test_len = round(total_len*test_p)\n",
    "    ivs_len = round(total_len*ivs_p)\n",
    "\n",
    "    model_len = train_len+test_len\n",
    "\n",
    "    total_used_len = model_len+ivs_len\n",
    "\n",
    "    train = arr[:train_len]\n",
    "    test = arr[train_len:model_len]\n",
    "    ivs = arr[model_len:total_used_len]\n",
    "\n",
    "    return train, test, ivs\n",
    "\n",
    "\n",
    "inside_train, inside_test, inside_ivs = split_data(inside_arr)\n",
    "\n",
    "print(\"train\")\n",
    "print(inside_train)\n",
    "print(\"test\")\n",
    "print(inside_test)\n",
    "print(\"ivs\")\n",
    "print(inside_ivs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Wanted Predictions: 5.0\n"
     ]
    }
   ],
   "source": [
    "# 2h30\n",
    "\n",
    "per_min = (2*60) + 30\n",
    "per_30_mins = per_min / 30\n",
    "\n",
    "print(\"Number of Wanted Predictions: \" + str(per_30_mins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-step-ahead (auto-regressive)\n",
    "<br>\n",
    "One-step-ahead (auto-regressive with exogenous inputs)\n",
    "<br>\n",
    "Recursive\n",
    "<br>\n",
    "MIMO\n",
    "<br>\n",
    "Direct\n",
    "<br>\n",
    "Hybrid (Recursive and Direct)\n",
    "<br>\n",
    "Hybrid (Direct and MIMO)\n",
    "<br>\n",
    "<br>\n",
    "MIMO is good too, but it would be more accurate and faster to compute several dedicated models for each step instead of all in a batch.\n",
    "<br>\n",
    "Direct and Hybrid(Direct and MIMO) are on top - they can execute all\n",
    "<br>\n",
    "<br>\n",
    "Hybrid(Direct and MIMO) = [2,2,1] predictive models\n",
    "<br>\n",
    "Direct = [+-,1,1,1,1] predictive models\n",
    "<br>\n",
    "<br>\n",
    "Other tests that could be implemented would be creating a Long Short-Term Memory model, trying out some kind of BERT model with months as categorial variables, or classical statistic models like SVMs or Decision Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_train_0 = []\n",
    "inside_train_X_0 = []\n",
    "inside_train_Y_0 = []\n",
    "\n",
    "imput_dim_df = 48 # 24H input\n",
    "\n",
    "_temp_arr = []\n",
    "_n = 0\n",
    "for temp, month, day, hour, minute in inside_train:\n",
    "    if len(_temp_arr) < imput_dim_df:\n",
    "        _temp_arr.append(temp)\n",
    "        _n+=1\n",
    "        continue\n",
    "    else:\n",
    "        _temp_arr.pop(0)\n",
    "        _temp_arr.append(temp)\n",
    "\n",
    "    if _n < len(inside_train)-1:\n",
    "        inside_train_X_0.append(_temp_arr)\n",
    "        inside_train_Y_0.append(inside_train[_n+1][0])\n",
    "        \n",
    "        inside_train_0.append((torch.Tensor(_temp_arr), inside_train[_n+1][0]))\n",
    "\n",
    "    _n+=1\n",
    "\n",
    "inside_train_X_0 = torch.from_numpy(np.array(inside_train_X_0, dtype=np.float16))\n",
    "inside_train_Y_0 = torch.from_numpy(np.array(inside_train_Y_0, dtype=np.float16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38661, 48])\n",
      "torch.Size([38661])\n"
     ]
    }
   ],
   "source": [
    "print(inside_train_X_0.size())\n",
    "print(inside_train_Y_0.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "n_iters = 38661\n",
    "num_epochs = n_iters / (len(inside_train_X_0) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=inside_train_0, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # 28 time steps\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 48\n",
    "hidden_dim = 48\n",
    "layer_dim = 1\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192, 48])\n",
      "torch.Size([192, 48])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([1, 48])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = [] # TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 22 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rapos\\OneDrive\\Desktop\\IT\\Dev\\Workspace\\IoT_TemperatureMonitoring\\main.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Calculate Loss: softmax --> cross entropy loss\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39;49mlong())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X33sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Getting gradients w.r.t. parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rapos/OneDrive/Desktop/IT/Dev/Workspace/IoT_TemperatureMonitoring/main.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\rapos\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 22 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\n",
    "seq_dim = 1  \n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as a torch tensor with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels.long())\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Resize images\n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055142e5cf66ed8ee87e97d9d29944a505c8696ace08c4c3475747b47f85af0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
